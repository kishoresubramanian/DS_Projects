{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/surekharamireddy/spam-detection-with-99-accuracy\n",
    "# https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976\n",
    "# https://stackoverflow.com/questions/54118076/how-to-resample-text-imbalanced-groups-in-a-pipeline\n",
    "# https://stackoverflow.com/questions/48758383/all-intermediate-steps-should-be-transformers-and-implement-fit-and-transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The Ling-Spam dataset is a collection of 2,893 spam and non-spam messages curated from the Linguist List. These messages focus on linguistic interests around job postings, research opportunities and software discussion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "#Import libs\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('messages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content - length : 3386 apple-iss research cen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lang classification grimes , joseph e . and ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>i am posting this inquiry for sergei atamas ( ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>risk</td>\n",
       "      <td>a colleague and i are researching the differin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier this morning i was on the phone with a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0            job posting - apple-iss research center   \n",
       "1                                                NaN   \n",
       "2  query : letter frequencies for text identifica...   \n",
       "3                                               risk   \n",
       "4                           request book information   \n",
       "\n",
       "                                             message  label  \n",
       "0  content - length : 3386 apple-iss research cen...      0  \n",
       "1  lang classification grimes , joseph e . and ba...      0  \n",
       "2  i am posting this inquiry for sergei atamas ( ...      0  \n",
       "3  a colleague and i are researching the differin...      0  \n",
       "4  earlier this morning i was on the phone with a...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2893, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all messages to lower case\n",
    "df['message'] = df['message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content - length : 3386 apple-iss research cen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lang classification grimes , joseph e . and ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>i am posting this inquiry for sergei atamas ( ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>risk</td>\n",
       "      <td>a colleague and i are researching the differin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier this morning i was on the phone with a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0            job posting - apple-iss research center   \n",
       "1                                                NaN   \n",
       "2  query : letter frequencies for text identifica...   \n",
       "3                                               risk   \n",
       "4                           request book information   \n",
       "\n",
       "                                             message  label  \n",
       "0  content - length : 3386 apple-iss research cen...      0  \n",
       "1  lang classification grimes , joseph e . and ba...      0  \n",
       "2  i am posting this inquiry for sergei atamas ( ...      0  \n",
       "3  a colleague and i are researching the differin...      0  \n",
       "4  earlier this morning i was on the phone with a...      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data once \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject    62\n",
       "message     0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checing null values \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sociolinguistics                                           8\n",
       "re :                                                       7\n",
       "conference announcement                                    6\n",
       "syntax                                                     6\n",
       "job announcement                                           5\n",
       "                                                          ..\n",
       "re : 8 . 1098 , qs : french , chinese poetry , bannock     1\n",
       "chechen                                                    1\n",
       "program on indigenous languages of brazil                  1\n",
       "mongolian programs                                         1\n",
       "lexical functional grammar conf : final call for papers    1\n",
       "Name: subject, Length: 2613, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sociolinguistics'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject'].mode().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "df=df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index      0\n",
       "subject    0\n",
       "message    0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's once again \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content - length : 3386 apple-iss research cen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>i am posting this inquiry for sergei atamas ( ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>risk</td>\n",
       "      <td>a colleague and i are researching the differin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier this morning i was on the phone with a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "      <td>content - length : 4437 call for papers is the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>2888</td>\n",
       "      <td>love your profile - ysuolvpv</td>\n",
       "      <td>hello thanks for stopping by ! ! we have taken...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>2889</td>\n",
       "      <td>you have been asked to join kiddin</td>\n",
       "      <td>the list owner of : \" kiddin \" has invited you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>2890</td>\n",
       "      <td>anglicization of composers ' names</td>\n",
       "      <td>judging from the return post , i must have sou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>2891</td>\n",
       "      <td>re : 6 . 797 , comparative method : n - ary co...</td>\n",
       "      <td>gotcha ! there are two separate fallacies in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2892</td>\n",
       "      <td>re : american - english in australia</td>\n",
       "      <td>hello ! i ' m working on a thesis concerning a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2831 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                            subject  \\\n",
       "0         0            job posting - apple-iss research center   \n",
       "1         2  query : letter frequencies for text identifica...   \n",
       "2         3                                               risk   \n",
       "3         4                           request book information   \n",
       "4         5  call for abstracts : optimality in syntactic t...   \n",
       "...     ...                                                ...   \n",
       "2826   2888                       love your profile - ysuolvpv   \n",
       "2827   2889                 you have been asked to join kiddin   \n",
       "2828   2890                 anglicization of composers ' names   \n",
       "2829   2891  re : 6 . 797 , comparative method : n - ary co...   \n",
       "2830   2892               re : american - english in australia   \n",
       "\n",
       "                                                message  label  \n",
       "0     content - length : 3386 apple-iss research cen...      0  \n",
       "1     i am posting this inquiry for sergei atamas ( ...      0  \n",
       "2     a colleague and i are researching the differin...      0  \n",
       "3     earlier this morning i was on the phone with a...      0  \n",
       "4     content - length : 4437 call for papers is the...      0  \n",
       "...                                                 ...    ...  \n",
       "2826  hello thanks for stopping by ! ! we have taken...      1  \n",
       "2827  the list owner of : \" kiddin \" has invited you...      1  \n",
       "2828  judging from the return post , i must have sou...      0  \n",
       "2829  gotcha ! there are two separate fallacies in t...      0  \n",
       "2830  hello ! i ' m working on a thesis concerning a...      0  \n",
       "\n",
       "[2831 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>subject+message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content - length : 3386 apple-iss research cen...</td>\n",
       "      <td>0</td>\n",
       "      <td>job posting - apple-iss research centercontent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>i am posting this inquiry for sergei atamas ( ...</td>\n",
       "      <td>0</td>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>risk</td>\n",
       "      <td>a colleague and i are researching the differin...</td>\n",
       "      <td>0</td>\n",
       "      <td>riska colleague and i are researching the diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier this morning i was on the phone with a...</td>\n",
       "      <td>0</td>\n",
       "      <td>request book informationearlier this morning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "      <td>content - length : 4437 call for papers is the...</td>\n",
       "      <td>0</td>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            subject  \\\n",
       "0      0            job posting - apple-iss research center   \n",
       "1      2  query : letter frequencies for text identifica...   \n",
       "2      3                                               risk   \n",
       "3      4                           request book information   \n",
       "4      5  call for abstracts : optimality in syntactic t...   \n",
       "\n",
       "                                             message  label  \\\n",
       "0  content - length : 3386 apple-iss research cen...      0   \n",
       "1  i am posting this inquiry for sergei atamas ( ...      0   \n",
       "2  a colleague and i are researching the differin...      0   \n",
       "3  earlier this morning i was on the phone with a...      0   \n",
       "4  content - length : 4437 call for papers is the...      0   \n",
       "\n",
       "                                     subject+message  \n",
       "0  job posting - apple-iss research centercontent...  \n",
       "1  query : letter frequencies for text identifica...  \n",
       "2  riska colleague and i are researching the diff...  \n",
       "3  request book informationearlier this morning i...  \n",
       "4  call for abstracts : optimality in syntactic t...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject+message']=df['subject']+df['message']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"salford seminarscontent - length : 2116 university of salford , uk european studies research institute ( esri ) centre for language and linguistics seminar programme 1995 the following seminars have been planned : wednesday 22 february ` what 's the use of dictionaries ? ' reinhard hartmann , essex monday 27 february ` first steps in learning french : a study of ( 5 . 30pm ) progression in the secondary school ' ros mitchell , southampton wednesday 8 march ` the nature of translation ' stephen thomas , salford wednesday 15 march ` the variational approach in translation ' myriam carr , salford wednesday 22 march ` the unit of translation ' michel ballard , artois wednesday 10 may ` pragmatic factors in syntactic change : a r&g college spanish case study ' christopher pountain , cambridge wednesday 17 may ` proper nouns , generics , and the count-mass r&g college distinction ' christopher lyons , salford seminars will take place at 4 . 30 in room g21 , crescent house , university of salford unless otherwise indicated . for further information , contact charlotte hoffmann , associate director , centre of language and linguistics , esri . tel : + 44 161 745 5990\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject+message'][54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                  2831\n",
       "unique                                                 2814\n",
       "top       re := 20 the virtual girlfriend and virtual bo...\n",
       "freq                                                      4\n",
       "Name: subject+message, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject+message'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length']=df['subject+message'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>subject+message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content - length : 3386 apple-iss research cen...</td>\n",
       "      <td>0</td>\n",
       "      <td>job posting - apple-iss research centercontent...</td>\n",
       "      <td>2895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>i am posting this inquiry for sergei atamas ( ...</td>\n",
       "      <td>0</td>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>risk</td>\n",
       "      <td>a colleague and i are researching the differin...</td>\n",
       "      <td>0</td>\n",
       "      <td>riska colleague and i are researching the diff...</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier this morning i was on the phone with a...</td>\n",
       "      <td>0</td>\n",
       "      <td>request book informationearlier this morning i...</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "      <td>content - length : 4437 call for papers is the...</td>\n",
       "      <td>0</td>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "      <td>4543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            subject  \\\n",
       "0      0            job posting - apple-iss research center   \n",
       "1      2  query : letter frequencies for text identifica...   \n",
       "2      3                                               risk   \n",
       "3      4                           request book information   \n",
       "4      5  call for abstracts : optimality in syntactic t...   \n",
       "\n",
       "                                             message  label  \\\n",
       "0  content - length : 3386 apple-iss research cen...      0   \n",
       "1  i am posting this inquiry for sergei atamas ( ...      0   \n",
       "2  a colleague and i are researching the differin...      0   \n",
       "3  earlier this morning i was on the phone with a...      0   \n",
       "4  content - length : 4437 call for papers is the...      0   \n",
       "\n",
       "                                     subject+message  length  \n",
       "0  job posting - apple-iss research centercontent...    2895  \n",
       "1  query : letter frequencies for text identifica...    1485  \n",
       "2  riska colleague and i are researching the diff...     328  \n",
       "3  request book informationearlier this morning i...    1070  \n",
       "4  call for abstracts : optimality in syntactic t...    4543  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now i'm going to drop un-necessary features \n",
    "df.drop('subject',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>subject+message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>content - length : 3386 apple-iss research cen...</td>\n",
       "      <td>0</td>\n",
       "      <td>job posting - apple-iss research centercontent...</td>\n",
       "      <td>2895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>i am posting this inquiry for sergei atamas ( ...</td>\n",
       "      <td>0</td>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a colleague and i are researching the differin...</td>\n",
       "      <td>0</td>\n",
       "      <td>riska colleague and i are researching the diff...</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>earlier this morning i was on the phone with a...</td>\n",
       "      <td>0</td>\n",
       "      <td>request book informationearlier this morning i...</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>content - length : 4437 call for papers is the...</td>\n",
       "      <td>0</td>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "      <td>4543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            message  label  \\\n",
       "0      0  content - length : 3386 apple-iss research cen...      0   \n",
       "1      2  i am posting this inquiry for sergei atamas ( ...      0   \n",
       "2      3  a colleague and i are researching the differin...      0   \n",
       "3      4  earlier this morning i was on the phone with a...      0   \n",
       "4      5  content - length : 4437 call for papers is the...      0   \n",
       "\n",
       "                                     subject+message  length  \n",
       "0  job posting - apple-iss research centercontent...    2895  \n",
       "1  query : letter frequencies for text identifica...    1485  \n",
       "2  riska colleague and i are researching the diff...     328  \n",
       "3  request book informationearlier this morning i...    1070  \n",
       "4  call for abstracts : optimality in syntactic t...    4543  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check it once \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clr=['red','green']\n",
    "plt.figure(figsize=(10,5),dpi=100)\n",
    "exp=(0.025,0)\n",
    "val=df['label'].value_counts().index.tolist()\n",
    "lb=df['label'].value_counts()\n",
    "plt.pie(lb,explode=exp,labels=val, autopct='%0.f%%',radius=1.5,colors=clr)\n",
    "plt.legend([\"0 = NO SPAM\",'1 = SPAM'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Email Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('message',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>subject+message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>job posting - apple-iss research centercontent...</td>\n",
       "      <td>2895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>riska colleague and i are researching the diff...</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>request book informationearlier this morning i...</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "      <td>4543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  label                                    subject+message  length\n",
       "0      0      0  job posting - apple-iss research centercontent...    2895\n",
       "1      2      0  query : letter frequencies for text identifica...    1485\n",
       "2      3      0  riska colleague and i are researching the diff...     328\n",
       "3      4      0  request book informationearlier this morning i...    1070\n",
       "4      5      0  call for abstracts : optimality in syntactic t...    4543"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVRTING EVERYTHING TO LOWERCASE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject+message']=df['subject+message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "        ... \n",
       "2826    True\n",
       "2827    True\n",
       "2828    True\n",
       "2829    True\n",
       "2830    True\n",
       "Name: subject+message, Length: 2831, dtype: bool"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject+message'].str.contains('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"query : letter frequencies for text identificationi am posting this inquiry for sergei atamas ( satamas @ umabnet . ab . umd . edu ) , a research associate at the university of maryland at baltimore . his field is molecular biology , and his work involves comparing dna strings using various algorithms . i do n't understand the details well enough to pass them along . at any rate , one such algorithm relies upon frequencies with which the letters g , a , t , and c occur in the dna strings . he would like to explore the analogous use of letter ( sound ) frequencies in natural language texts . hence this posting . specifically , sergei wonders if any linguist subscribers could help steer him to recent literature concerning text identification based on letter frequencies . any suggestions could be sent directly to him at the above address , or to me and i ' ll pass them along . he would also be interested in collaborative work if this research connects with the work of any linguists or text processing specialists . he observes that very often work in one field would actually help work in a far-removed field , if only people knew what was going on over there . george fowler george fowler gfowler @ indiana . edu [ email ] dept . of slavic languages * * 1-317 - 726-1482 [ home ] * * [ try here first ! ] ballantine 502 1-812 - 855-2624 / - 2608 / - 9906 [ dept . ] indiana university 1-812 - 855-2829 [ office ] bloomington , in 47405 usa 1-812 - 855-2107 [ dept . fax ]\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject+message'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing newline( \\n ) with Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject+message']=df['subject+message'].str.replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "2826    False\n",
       "2827    False\n",
       "2828    False\n",
       "2829    False\n",
       "2830    False\n",
       "Name: subject+message, Length: 2831, dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject+message'].str.contains('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPLACING URL's BY 'LINKS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.youtube.com/watch?v=WuuyD3Yr-js']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "#x='https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html'\n",
    "x='https://www.youtube.com/watch?v=WuuyD3Yr-js'\n",
    "ur=re.findall(r'http[s]?://(?:[a-zA-Z0-9]|[./?-]|[=])+',x)  \n",
    "# IF YOU WANT TO MATCH WITH QUESTIONMARK(?) DONT PLACE THE QUESTION MARK IN THE END OR STARTING OF THE BRACKETS() \n",
    "# BECOZ IT WILL GIVE SOME ERROR\n",
    "ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject+message']=df['subject+message'].str.replace(r'http[s]?://(?:[a-zA-Z0-9]|[./?-]|[=])+','Links')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPLACING CURRENCY SIGNS BY 'MONEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>subject+message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, label, subject+message, length]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['subject+message'].str.contains(r'£')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>subject+message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>job posting - apple-iss research centercontent...</td>\n",
       "      <td>2895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>riska colleague and i are researching the diff...</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>request book informationearlier this morning i...</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "      <td>4543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>2888</td>\n",
       "      <td>1</td>\n",
       "      <td>love your profile - ysuolvpvhello thanks for s...</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>2889</td>\n",
       "      <td>1</td>\n",
       "      <td>you have been asked to join kiddinthe list own...</td>\n",
       "      <td>2197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>2890</td>\n",
       "      <td>0</td>\n",
       "      <td>anglicization of composers ' namesjudging from...</td>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>2891</td>\n",
       "      <td>0</td>\n",
       "      <td>re : 6 . 797 , comparative method : n - ary co...</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2892</td>\n",
       "      <td>0</td>\n",
       "      <td>re : american - english in australiahello ! i ...</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2831 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  label                                    subject+message  length\n",
       "0         0      0  job posting - apple-iss research centercontent...    2895\n",
       "1         2      0  query : letter frequencies for text identifica...    1485\n",
       "2         3      0  riska colleague and i are researching the diff...     328\n",
       "3         4      0  request book informationearlier this morning i...    1070\n",
       "4         5      0  call for abstracts : optimality in syntactic t...    4543\n",
       "...     ...    ...                                                ...     ...\n",
       "2826   2888      1  love your profile - ysuolvpvhello thanks for s...     290\n",
       "2827   2889      1  you have been asked to join kiddinthe list own...    2197\n",
       "2828   2890      0  anglicization of composers ' namesjudging from...    1073\n",
       "2829   2891      0  re : 6 . 797 , comparative method : n - ary co...    3003\n",
       "2830   2892      0  re : american - english in australiahello ! i ...     736\n",
       "\n",
       "[2831 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['subject+message'].str.contains(r'$')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject+message']=df['subject+message'].str.replace(r'\\$', 'Money')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPLACING LARGE WHITE SPACE BY SINGLE WHITE SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject+message']=df['subject+message'].str.replace(r'\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>subject+message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>job posting - apple-iss research centercontent...</td>\n",
       "      <td>2895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>riska colleague and i are researching the diff...</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>request book informationearlier this morning i...</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "      <td>4543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>2888</td>\n",
       "      <td>1</td>\n",
       "      <td>love your profile - ysuolvpvhello thanks for s...</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>2889</td>\n",
       "      <td>1</td>\n",
       "      <td>you have been asked to join kiddinthe list own...</td>\n",
       "      <td>2197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>2890</td>\n",
       "      <td>0</td>\n",
       "      <td>anglicization of composers ' namesjudging from...</td>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>2891</td>\n",
       "      <td>0</td>\n",
       "      <td>re : 6 . 797 , comparative method : n - ary co...</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2892</td>\n",
       "      <td>0</td>\n",
       "      <td>re : american - english in australiahello ! i ...</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2831 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  label                                    subject+message  length\n",
       "0         0      0  job posting - apple-iss research centercontent...    2895\n",
       "1         2      0  query : letter frequencies for text identifica...    1485\n",
       "2         3      0  riska colleague and i are researching the diff...     328\n",
       "3         4      0  request book informationearlier this morning i...    1070\n",
       "4         5      0  call for abstracts : optimality in syntactic t...    4543\n",
       "...     ...    ...                                                ...     ...\n",
       "2826   2888      1  love your profile - ysuolvpvhello thanks for s...     290\n",
       "2827   2889      1  you have been asked to join kiddinthe list own...    2197\n",
       "2828   2890      0  anglicization of composers ' namesjudging from...    1073\n",
       "2829   2891      0  re : 6 . 797 , comparative method : n - ary co...    3003\n",
       "2830   2892      0  re : american - english in australiahello ! i ...     736\n",
       "\n",
       "[2831 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['subject+message'].str.contains(r'^\\s+|\\s+?$', '')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPLACING MOBILE NO AS CONTACT NUMBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject+message']=df['subject+message'].str.replace(r'([\\(]*\\d{3}[\\s-]\\d{3}[\\s-]\\d{4}[\\)]*)','contact number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['213-456-6784']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x='(213-456-6784)'\n",
    "x='213-456-6784'\n",
    "contact=re.findall(r'([\\(]*\\d{3}[\\s-]\\d{3}[\\s-]\\d{4}[\\)]*)',x)\n",
    "contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>subject+message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>icslp 96= = = = = = = = = = = = = = = = = = = ...</td>\n",
       "      <td>11464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>salford seminarscontent - length : 2116 univer...</td>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>conf : translating literature and filmuniversi...</td>\n",
       "      <td>2247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>holding / managing / handi am looking at seman...</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>grammatical relations and derived notionsabout...</td>\n",
       "      <td>2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>2600</td>\n",
       "      <td>0</td>\n",
       "      <td>austronesian linguisticsmarian klamer a gramma...</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>2603</td>\n",
       "      <td>0</td>\n",
       "      <td>negation : syntax , semantics and pragmaticsun...</td>\n",
       "      <td>9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>2772</td>\n",
       "      <td>0</td>\n",
       "      <td>a linguistics consulting assignment ( correcti...</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>2777</td>\n",
       "      <td>0</td>\n",
       "      <td>adjectives , terminology , follow-upcolleagues...</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>2839</td>\n",
       "      <td>1</td>\n",
       "      <td>advertise to millions and millions for free ! ...</td>\n",
       "      <td>5284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  label                                    subject+message  length\n",
       "39       41      0  icslp 96= = = = = = = = = = = = = = = = = = = ...   11464\n",
       "54       56      0  salford seminarscontent - length : 2116 univer...    1178\n",
       "60       62      0  conf : translating literature and filmuniversi...    2247\n",
       "62       64      0  holding / managing / handi am looking at seman...     802\n",
       "73       76      0  grammatical relations and derived notionsabout...    2772\n",
       "...     ...    ...                                                ...     ...\n",
       "2539   2600      0  austronesian linguisticsmarian klamer a gramma...    2010\n",
       "2542   2603      0  negation : syntax , semantics and pragmaticsun...    9665\n",
       "2711   2772      0  a linguistics consulting assignment ( correcti...    1503\n",
       "2716   2777      0  adjectives , terminology , follow-upcolleagues...     681\n",
       "2777   2839      1  advertise to millions and millions for free ! ...    5284\n",
       "\n",
       "[157 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['subject+message'].str.contains('contact number')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPLACING SPECIAL CHARACTERS  BY WHITE SPACE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject+message']=df['subject+message'].str.replace(r\"[^a-zA-Z0-9]+\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPLACING NUMBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject+message']=df['subject+message'].str.replace(r'\\d+(\\.\\d+)?','numbers') # even it will replace decimal numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['subject+message'][39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>subject+message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>job posting apple iss research centercontent l...</td>\n",
       "      <td>2895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>query letter frequencies for text identificati...</td>\n",
       "      <td>1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>riska colleague and i are researching the diff...</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>request book informationearlier this morning i...</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>call for abstracts optimality in syntactic the...</td>\n",
       "      <td>4543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  label                                    subject+message  length\n",
       "0      0      0  job posting apple iss research centercontent l...    2895\n",
       "1      2      0  query letter frequencies for text identificati...    1485\n",
       "2      3      0  riska colleague and i are researching the diff...     328\n",
       "3      4      0  request book informationearlier this morning i...    1070\n",
       "4      5      0  call for abstracts optimality in syntactic the...    4543"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "df['Cleaned_text']= df['subject+message'].apply(lambda x:' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>subject+message</th>\n",
       "      <th>length</th>\n",
       "      <th>Cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>2888</td>\n",
       "      <td>1</td>\n",
       "      <td>love your profile ysuolvpvhello thanks for sto...</td>\n",
       "      <td>290</td>\n",
       "      <td>love profile ysuolvpvhello thanks stopping tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>2889</td>\n",
       "      <td>1</td>\n",
       "      <td>you have been asked to join kiddinthe list own...</td>\n",
       "      <td>2197</td>\n",
       "      <td>asked join kiddinthe list owner kiddin invited...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>2890</td>\n",
       "      <td>0</td>\n",
       "      <td>anglicization of composers namesjudging from t...</td>\n",
       "      <td>1073</td>\n",
       "      <td>anglicization composers namesjudging return po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>2891</td>\n",
       "      <td>0</td>\n",
       "      <td>re numbers numbers comparative method n ary co...</td>\n",
       "      <td>3003</td>\n",
       "      <td>numbers numbers comparative method n ary compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2892</td>\n",
       "      <td>0</td>\n",
       "      <td>re american english in australiahello i m work...</td>\n",
       "      <td>736</td>\n",
       "      <td>american english australiahello working thesis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  label                                    subject+message  length  \\\n",
       "2826   2888      1  love your profile ysuolvpvhello thanks for sto...     290   \n",
       "2827   2889      1  you have been asked to join kiddinthe list own...    2197   \n",
       "2828   2890      0  anglicization of composers namesjudging from t...    1073   \n",
       "2829   2891      0  re numbers numbers comparative method n ary co...    3003   \n",
       "2830   2892      0  re american english in australiahello i m work...     736   \n",
       "\n",
       "                                           Cleaned_text  \n",
       "2826  love profile ysuolvpvhello thanks stopping tak...  \n",
       "2827  asked join kiddinthe list owner kiddin invited...  \n",
       "2828  anglicization composers namesjudging return po...  \n",
       "2829  numbers numbers comparative method n ary compa...  \n",
       "2830  american english australiahello working thesis...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>subject+message</th>\n",
       "      <th>length</th>\n",
       "      <th>Cleaned_text</th>\n",
       "      <th>lgth_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>job posting apple iss research centercontent l...</td>\n",
       "      <td>2895</td>\n",
       "      <td>job posting apple iss research centercontent l...</td>\n",
       "      <td>2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>query letter frequencies for text identificati...</td>\n",
       "      <td>1485</td>\n",
       "      <td>query letter frequencies text identificationi ...</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>riska colleague and i are researching the diff...</td>\n",
       "      <td>328</td>\n",
       "      <td>riska colleague researching differing degrees ...</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>request book informationearlier this morning i...</td>\n",
       "      <td>1070</td>\n",
       "      <td>request book informationearlier morning phone ...</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>call for abstracts optimality in syntactic the...</td>\n",
       "      <td>4543</td>\n",
       "      <td>call abstracts optimality syntactic theorycont...</td>\n",
       "      <td>3472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  label                                    subject+message  length  \\\n",
       "0      0      0  job posting apple iss research centercontent l...    2895   \n",
       "1      2      0  query letter frequencies for text identificati...    1485   \n",
       "2      3      0  riska colleague and i are researching the diff...     328   \n",
       "3      4      0  request book informationearlier this morning i...    1070   \n",
       "4      5      0  call for abstracts optimality in syntactic the...    4543   \n",
       "\n",
       "                                        Cleaned_text  lgth_clean  \n",
       "0  job posting apple iss research centercontent l...        2108  \n",
       "1  query letter frequencies text identificationi ...        1150  \n",
       "2  riska colleague researching differing degrees ...         216  \n",
       "3  request book informationearlier morning phone ...         653  \n",
       "4  call abstracts optimality syntactic theorycont...        3472  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lgth_clean']=df['Cleaned_text'].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_length=sum(df['length'])\n",
    "after_cleaning=sum(df['lgth_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_length 9278085\n",
      "after_cleaning 6717291\n"
     ]
    }
   ],
   "source": [
    "print(\"original_length\",original_length)\n",
    "print('after_cleaning',after_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>subject+message</th>\n",
       "      <th>length</th>\n",
       "      <th>Cleaned_text</th>\n",
       "      <th>lgth_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>job posting apple iss research centercontent l...</td>\n",
       "      <td>2895</td>\n",
       "      <td>job posting apple iss research centercontent l...</td>\n",
       "      <td>2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>query letter frequencies for text identificati...</td>\n",
       "      <td>1485</td>\n",
       "      <td>query letter frequencies text identificationi ...</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>riska colleague and i are researching the diff...</td>\n",
       "      <td>328</td>\n",
       "      <td>riska colleague researching differing degrees ...</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>request book informationearlier this morning i...</td>\n",
       "      <td>1070</td>\n",
       "      <td>request book informationearlier morning phone ...</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>call for abstracts optimality in syntactic the...</td>\n",
       "      <td>4543</td>\n",
       "      <td>call abstracts optimality syntactic theorycont...</td>\n",
       "      <td>3472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>2888</td>\n",
       "      <td>1</td>\n",
       "      <td>love your profile ysuolvpvhello thanks for sto...</td>\n",
       "      <td>290</td>\n",
       "      <td>love profile ysuolvpvhello thanks stopping tak...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>2889</td>\n",
       "      <td>1</td>\n",
       "      <td>you have been asked to join kiddinthe list own...</td>\n",
       "      <td>2197</td>\n",
       "      <td>asked join kiddinthe list owner kiddin invited...</td>\n",
       "      <td>1246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>2890</td>\n",
       "      <td>0</td>\n",
       "      <td>anglicization of composers namesjudging from t...</td>\n",
       "      <td>1073</td>\n",
       "      <td>anglicization composers namesjudging return po...</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>2891</td>\n",
       "      <td>0</td>\n",
       "      <td>re numbers numbers comparative method n ary co...</td>\n",
       "      <td>3003</td>\n",
       "      <td>numbers numbers comparative method n ary compa...</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2892</td>\n",
       "      <td>0</td>\n",
       "      <td>re american english in australiahello i m work...</td>\n",
       "      <td>736</td>\n",
       "      <td>american english australiahello working thesis...</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2831 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  label                                    subject+message  length  \\\n",
       "0         0      0  job posting apple iss research centercontent l...    2895   \n",
       "1         2      0  query letter frequencies for text identificati...    1485   \n",
       "2         3      0  riska colleague and i are researching the diff...     328   \n",
       "3         4      0  request book informationearlier this morning i...    1070   \n",
       "4         5      0  call for abstracts optimality in syntactic the...    4543   \n",
       "...     ...    ...                                                ...     ...   \n",
       "2826   2888      1  love your profile ysuolvpvhello thanks for sto...     290   \n",
       "2827   2889      1  you have been asked to join kiddinthe list own...    2197   \n",
       "2828   2890      0  anglicization of composers namesjudging from t...    1073   \n",
       "2829   2891      0  re numbers numbers comparative method n ary co...    3003   \n",
       "2830   2892      0  re american english in australiahello i m work...     736   \n",
       "\n",
       "                                           Cleaned_text  lgth_clean  \n",
       "0     job posting apple iss research centercontent l...        2108  \n",
       "1     query letter frequencies text identificationi ...        1150  \n",
       "2     riska colleague researching differing degrees ...         216  \n",
       "3     request book informationearlier morning phone ...         653  \n",
       "4     call abstracts optimality syntactic theorycont...        3472  \n",
       "...                                                 ...         ...  \n",
       "2826  love profile ysuolvpvhello thanks stopping tak...         153  \n",
       "2827  asked join kiddinthe list owner kiddin invited...        1246  \n",
       "2828  anglicization composers namesjudging return po...         672  \n",
       "2829  numbers numbers comparative method n ary compa...        1986  \n",
       "2830  american english australiahello working thesis...         468  \n",
       "\n",
       "[2831 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted Variables\n",
    "df=df.drop(['index','length','subject+message','lgth_clean'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>job posting apple iss research centercontent l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>query letter frequencies text identificationi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>riska colleague researching differing degrees ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>request book informationearlier morning phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>call abstracts optimality syntactic theorycont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>1</td>\n",
       "      <td>love profile ysuolvpvhello thanks stopping tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>1</td>\n",
       "      <td>asked join kiddinthe list owner kiddin invited...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>0</td>\n",
       "      <td>anglicization composers namesjudging return po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>0</td>\n",
       "      <td>numbers numbers comparative method n ary compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>0</td>\n",
       "      <td>american english australiahello working thesis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2831 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                       Cleaned_text\n",
       "0         0  job posting apple iss research centercontent l...\n",
       "1         0  query letter frequencies text identificationi ...\n",
       "2         0  riska colleague researching differing degrees ...\n",
       "3         0  request book informationearlier morning phone ...\n",
       "4         0  call abstracts optimality syntactic theorycont...\n",
       "...     ...                                                ...\n",
       "2826      1  love profile ysuolvpvhello thanks stopping tak...\n",
       "2827      1  asked join kiddinthe list owner kiddin invited...\n",
       "2828      0  anglicization composers namesjudging return po...\n",
       "2829      0  numbers numbers comparative method n ary compa...\n",
       "2830      0  american english australiahello working thesis...\n",
       "\n",
       "[2831 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['Cleaned_text']\n",
    "Y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2831,)\n",
      "(2831,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    job posting apple iss research centercontent l...\n",
       "1    query letter frequencies text identificationi ...\n",
       "2    riska colleague researching differing degrees ...\n",
       "3    request book informationearlier morning phone ...\n",
       "4    call abstracts optimality syntactic theorycont...\n",
       "Name: Cleaned_text, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spam=df[df.label==0]\n",
    "Normal=df[df.label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2363, 2) (468, 2)\n"
     ]
    }
   ],
   "source": [
    "print(Spam.shape,Normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "2826    1\n",
       "2827    1\n",
       "2828    0\n",
       "2829    0\n",
       "2830    0\n",
       "Name: label, Length: 2831, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'X' can be array or DataFrame\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(max_features=5000)\n",
    "X_tf = tf.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.11516803, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tf[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2831, 5000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'X_tf' and 'Y' can be array or DataFrame<br>\n",
    "# here I have passed X_tf' and 'Y' as an array<br>\n",
    "from imblearn.combine import SMOTETomek\n",
    "smk=SMOTETomek(random_state=42)\n",
    "X_new,Y_new=smk.fit_sample(X_tf,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4726, 5000) (4726,)\n"
     ]
    }
   ],
   "source": [
    "print(X_new.shape,Y_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.11516803, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_new,Y_new, test_size = 0.3, random_state = 225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3308, 5000) (1418, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[696   3]\n",
      " [  3 716]]\n",
      "Accuracy :  0.995768688293371\n",
      "Precision :  0.995768688293371\n",
      "Recall :  0.995768688293371\n"
     ]
    }
   ],
   "source": [
    "# Just for Testing Created\n",
    "\n",
    "# lr = LogisticRegression()\n",
    "# logistic=lr.fit(X_train,Y_train)\n",
    "# y_pred = logistic.predict(X_test)\n",
    "# print(confusion_matrix(y_pred,Y_test))\n",
    "# print(\"Accuracy : \", accuracy_score(y_pred,Y_test))\n",
    "# print(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\n",
    "# print(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "knc = KNeighborsClassifier()\n",
    "abc = AdaBoostClassifier()\n",
    "mnb = MultinomialNB()\n",
    "gbc = GradientBoostingClassifier()\n",
    "rfc = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------LogisticRegression()----------------\n",
      "[[696   3]\n",
      " [  3 716]]\n",
      "Accuracy :  0.995768688293371\n",
      "Precision :  0.995768688293371\n",
      "Recall :  0.995768688293371\n",
      "-----------------KNeighborsClassifier()----------------\n",
      "[[266   0]\n",
      " [433 719]]\n",
      "Accuracy :  0.6946403385049366\n",
      "Precision :  0.883797324810176\n",
      "Recall :  0.6946403385049366\n",
      "-----------------AdaBoostClassifier()----------------\n",
      "[[693   5]\n",
      " [  6 714]]\n",
      "Accuracy :  0.9922425952045134\n",
      "Precision :  0.9922437444203571\n",
      "Recall :  0.9922425952045134\n",
      "-----------------MultinomialNB()----------------\n",
      "[[692   1]\n",
      " [  7 718]]\n",
      "Accuracy :  0.9943582510578279\n",
      "Precision :  0.9943947397132616\n",
      "Recall :  0.9943582510578279\n",
      "-----------------GradientBoostingClassifier()----------------\n",
      "[[694   7]\n",
      " [  5 712]]\n",
      "Accuracy :  0.9915373765867419\n",
      "Precision :  0.9915410192782318\n",
      "Recall :  0.9915373765867419\n",
      "-----------------RandomForestClassifier(random_state=42)----------------\n",
      "[[697   2]\n",
      " [  2 717]]\n",
      "Accuracy :  0.997179125528914\n",
      "Precision :  0.997179125528914\n",
      "Recall :  0.997179125528914\n"
     ]
    }
   ],
   "source": [
    "algorithms=[lr,knc,abc,mnb,gbc,rfc]\n",
    "for i in algorithms:\n",
    "    model=i.fit(X_train,Y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('-----------------{}----------------'.format(i))\n",
    "    print(confusion_matrix(y_pred,Y_test))\n",
    "    print(\"Accuracy : \", accuracy_score(y_pred,Y_test))\n",
    "    print(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\n",
    "    print(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BY USING ABOVE TECHNIQUE WE CANT PREDICT NEW OUTPUT VARIABLE \n",
    "# AS NEW O/P WILL BE IN TEXT DATA SO BEFORE PREDICTING WE NEED TO DO TFIDF TRANFORM, AS IT CANT BE DONE\n",
    "# TO OVERCOME THIS PROBLEM WE WILL BE USING PIPELINE TECHNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-a1ed6eaf75e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'your microsoft account has been compromised'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m',you must update before or else your account going to close click to update'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "result=logistic.predict[['your microsoft account has been compromised'] [',you must update before or else your account going to close click to update']]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1 features per sample; expecting 5000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-e0f15c63c235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'your microsoft account has been compromised'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'you must update before or else your account going to close click to update'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 287\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1 features per sample; expecting 5000"
     ]
    }
   ],
   "source": [
    "result=logistic.predict([['your microsoft account has been compromised'],['you must update before or else your account going to close click to update']])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BY THIS STACKOVERFLOW METHOD WE HAVE CREATED CREATED THE PIPELINE\n",
    "# https://stackoverflow.com/questions/54118076/how-to-resample-text-imbalanced-groups-in-a-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type of the data inside TfidfVectorizer should be Series or Dataframe becoz TfidfVectorizer converts data into lower, \n",
    "# since numpy array has no lower operation so it throws error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-dc54f674298d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                   \u001b[0;34m(\u001b[0m\u001b[0;34m'smk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                   ('clf', LogisticRegression())])\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    279\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    231\u001b[0m                     \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m                 )\n\u001b[1;32m    235\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_resample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \"\"\"\n\u001b[1;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1199\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "model = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                  ('smk', SMOTETomek(random_state=42)),\n",
    "                  ('clf', LogisticRegression())])\n",
    "model = model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_pred,Y_test))\n",
    "print(\"Accuracy : \", accuracy_score(y_pred,Y_test))\n",
    "print(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\n",
    "print(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/48758383/all-intermediate-steps-should-be-transformers-and-implement-fit-and-transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we below error we will get if we apply 2 ML Algorithms in the PIPELINE\n",
    "# All intermediate steps of the chain should be estimators that implement fit and transform or fit_resample (but not both) or be a string 'passthrough' 'LogisticRegression()' (type <class 'sklearn.linear_model._logistic.LogisticRegression'>) doesn't)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE :\n",
    "## Sequentially(In_Order) apply a list of transforms and a final estimator. Intermediate steps of pipeline must implement fit and transform methods and the final estimator only needs to implement fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new, Y_new in in Numpy Array\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_new,Y_new, test_size = 0.3, random_state = 225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Cleaned_text'], df['label'] are in Series format\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['Cleaned_text'],df['label'], test_size = 0.3, random_state = 225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Applying OverSAmpling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WE ARE USING NAIVE BAYE'S ALGORITHM IN PIPELINE SINCE ITS PERFORMING BETTER than other Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[711 117]\n",
      " [  0  22]]\n",
      "Accuracy :  0.8623529411764705\n",
      "Precision :  0.9782141345746932\n",
      "Recall :  0.8623529411764705\n"
     ]
    }
   ],
   "source": [
    "#model = Pipeline([('tf_vectorizer',tvec),('SMOTETomek',smk)])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pipe = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                  ('clf', MultinomialNB())])\n",
    "pipe = pipe.fit(X_train, Y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_pred,Y_test))\n",
    "print(\"Accuracy : \", accuracy_score(y_pred,Y_test))\n",
    "print(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\n",
    "print(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WE ARE USING NAIVE BAYE'S ALGORITHM IN PIPELINE SINCE ITS PERFORMING BETTER than other Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BY Applying Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[704   1]\n",
      " [  7 138]]\n",
      "Accuracy :  0.9905882352941177\n",
      "Precision :  0.9906069485439201\n",
      "Recall :  0.9905882352941177\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                 ('smk', SMOTETomek(random_state=42)),\n",
    "                 ('clf', MultinomialNB())])\n",
    "pipe = pipe.fit(X_train, Y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_pred,Y_test))\n",
    "print(\"Accuracy : \", accuracy_score(y_pred,Y_test))\n",
    "print(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\n",
    "print(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We cant apply two nlp algorithms CountVectorizer and TfidfVectorizer as well as we cant apply two ML Algorithms in a PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-728f7ce96264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0;34m'smk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     ('clf', MultinomialNB())])\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    279\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    231\u001b[0m                     \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m                 )\n\u001b[1;32m    235\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_resample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \"\"\"\n\u001b[1;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1199\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([  ('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfVectorizer()),\n",
    "                    ('smk', SMOTETomek(random_state=42)),\n",
    "                    ('clf', MultinomialNB())])\n",
    "pipe = pipe.fit(X_train, Y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_pred,Y_test))\n",
    "print(\"Accuracy : \", accuracy_score(y_pred,Y_test))\n",
    "print(\"Precision : \", precision_score(y_pred,Y_test, average = 'weighted'))\n",
    "print(\"Recall : \", recall_score(y_pred,Y_test, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2483    french grad student conferenceappel de communi...\n",
       "146     studies sla hungarian currently writing phd se...\n",
       "556     tried calling please call free internet servic...\n",
       "1054    serious future future comes opportunity capita...\n",
       "2339    conference leuven numbers numbers numbers numb...\n",
       "                              ...                        \n",
       "2093    numbers numbers languagesin context speaks lan...\n",
       "2303    numbersth int workshop parsing technologies pr...\n",
       "1198    transcription workshop coling aclnumbers call ...\n",
       "498     nineteenth south asian languages analysis roun...\n",
       "2336    sociolinguisticsmichael g smith language power...\n",
       "Name: Cleaned_text, Length: 1981, dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pipe.predict(['your microsoft account has been compromised ,you must update before or else your account going to close click to update'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pipe.predict(['Today we want to inform you that the application period for 15.000 free Udacity Scholarships in Data Science is now open! Please apply by November 16th, 2020 via https://www.udacity.com/bertelsmann-tech-scholarships.'])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here 0 is spam and 1 is normal message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  EOF DONE CLASSIFICATION OF SPAM CLASSIFICATION "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
